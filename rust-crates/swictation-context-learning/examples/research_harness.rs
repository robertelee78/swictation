//! Phase 3 Research Harness
//!
//! Run complete validation experiment:
//! 1. Load segment data from metrics.db
//! 2. Split into train/test (80/20)
//! 3. Train context model
//! 4. Evaluate on test data
//! 5. Generate research report

use anyhow::Result;
use std::path::PathBuf;
use swictation_context_learning::{train_test_split, ContextLearner, LearningConfig};

fn main() -> Result<()> {
    // Initialize logging
    tracing_subscriber::fmt::init();

    println!("=== Phase 3 Context Learning Research Harness ===\n");

    // Configuration
    let db_path = dirs::data_local_dir()
        .unwrap_or_else(|| PathBuf::from(".local/share"))
        .join("swictation/metrics.db");

    println!("ğŸ“Š Configuration:");
    println!("  Database: {:?}", db_path);
    println!("  Train/test split: 80/20");
    println!("  Minimum segments: 50");
    println!("  Topic clusters: 5");
    println!("  Context window: 10 segments");
    println!("  Meta-learning: Enabled (depth=3)");
    println!();

    // Create learner
    let config = LearningConfig {
        min_segments: 50,
        num_topics: 5,
        context_window: 10,
        min_confidence: 0.70,
        enable_meta_learning: true,
        max_meta_depth: 3,
    };

    let mut learner = ContextLearner::new(config.clone());

    // Load data
    println!("ğŸ“‚ Loading training data...");
    let data = learner.load_training_data(&db_path, 6)?; // Last 6 months

    println!("  âœ“ Loaded {} segments", data.segments.len());
    println!("  âœ“ Total words: {}", data.total_words);
    println!("  âœ“ Date range: {} days", data.date_range_days);
    println!();

    if data.segments.len() < config.min_segments {
        eprintln!(
            "âŒ Insufficient data: {} segments (need {})",
            data.segments.len(),
            config.min_segments
        );
        eprintln!("   Run swictation for a while to collect more segment data.");
        return Ok(());
    }

    // Split data
    println!("âœ‚ï¸  Splitting data (80% train, 20% test)...");
    let (train_segments, test_segments) = train_test_split(&data, 0.80);
    println!("  âœ“ Training: {} segments", train_segments.len());
    println!("  âœ“ Testing: {} segments", test_segments.len());
    println!();

    // Train model
    println!("ğŸ§  Training context model...");
    let train_data = swictation_context_learning::TrainingData {
        segments: train_segments,
        total_words: data.total_words,
        date_range_days: data.date_range_days,
    };

    let model = learner.train(&train_data)?;
    println!("  âœ“ Discovered {} topic clusters", model.topics.len());
    println!("  âœ“ Learned {} homonym rules", model.homonym_rules.len());
    println!("  âœ“ Extracted {} context patterns", model.patterns.len());
    println!();

    // Meta-learning summary
    if let Some(summary) = learner.get_meta_summary() {
        println!("ğŸ”® Meta-Learning Summary:");
        for line in summary.lines() {
            println!("  {}", line);
        }
        println!();
    }

    // Evaluate
    println!("ğŸ“ˆ Evaluating on test data...");
    let report = learner.evaluate(&model, &test_segments)?;

    println!("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘          PHASE 3 RESEARCH RESULTS                     â•‘");
    println!("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£");
    println!("â•‘                                                       â•‘");
    println!(
        "â•‘  Topic Clustering Accuracy:    {:.1}%                   â•‘",
        report.topic_accuracy * 100.0
    );
    println!(
        "â•‘  Homonym Resolution Accuracy:  {:.1}%                   â•‘",
        report.homonym_accuracy * 100.0
    );
    println!(
        "â•‘  Overall Context Accuracy:     {:.1}%                   â•‘",
        report.context_accuracy * 100.0
    );
    println!("â•‘                                                       â•‘");
    println!("â•‘  Baseline (random guess):      67.0%                  â•‘");
    println!(
        "â•‘  Improvement:                  {:+.1}%                  â•‘",
        report.improvement_percentage
    );
    println!("â•‘                                                       â•‘");
    println!("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£");
    println!("â•‘  Safety Validation                                    â•‘");
    println!("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£");
    println!("â•‘                                                       â•‘");
    println!(
        "â•‘  No harmful patterns:         {}                     â•‘",
        if report.safety_checks.no_harmful_patterns {
            "âœ“ PASS"
        } else {
            "âœ— FAIL"
        }
    );
    println!(
        "â•‘  No profanity learning:       {}                     â•‘",
        if report.safety_checks.no_profanity_learning {
            "âœ“ PASS"
        } else {
            "âœ— FAIL"
        }
    );
    println!(
        "â•‘  Confidence threshold met:    {}                     â•‘",
        if report.safety_checks.confidence_threshold_met {
            "âœ“ PASS"
        } else {
            "âœ— FAIL"
        }
    );
    println!("â•‘                                                       â•‘");
    println!(
        "â•‘  All safety checks:           {}                     â•‘",
        if report.safety_checks.all_checks_passed {
            "âœ“ PASSED"
        } else {
            "âœ— FAILED"
        }
    );
    println!("â•‘                                                       â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    // Discovered topics
    println!("ğŸ“š Discovered Topic Clusters:");
    for (i, topic) in model.topics.iter().enumerate() {
        println!(
            "  {}. {} (confidence: {:.0}%, {} segments)",
            i + 1,
            topic.name,
            topic.confidence * 100.0,
            topic.segment_count
        );
        println!("     Keywords: {}", topic.keywords.join(", "));
    }
    println!();

    // Homonym rules
    if !model.homonym_rules.is_empty() {
        println!("ğŸ”¤ Learned Homonym Resolution Rules:");
        for (word, resolver) in model.homonym_rules.iter().take(5) {
            println!("  \"{}\":", word);
            for (i, interp) in resolver.interpretations.iter().take(3).enumerate() {
                println!(
                    "    {}. {} (confidence: {:.0}%, freq: {})",
                    i + 1,
                    interp.meaning,
                    interp.confidence * 100.0,
                    interp.frequency
                );
            }
        }
        println!();
    }

    // Context patterns
    if !model.patterns.is_empty() {
        println!("ğŸ” Top Context Patterns:");
        for (i, pattern) in model.patterns.iter().take(10).enumerate() {
            println!(
                "  {}. {} (support: {})",
                i + 1,
                pattern.description,
                pattern.support
            );
        }
        println!();
    }

    // Recommendation
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘  RECOMMENDATION                                       â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    if report.improvement_percentage >= 10.0 && report.safety_checks.all_checks_passed {
        println!("âœ… DEPLOY TO PRODUCTION");
        println!();
        println!(
            "Context-aware meta-learning provides {:.1}% improvement",
            report.improvement_percentage
        );
        println!("over baseline with acceptable safety profile.");
        println!();
        println!("Suggested next steps:");
        println!("1. Integrate ContextModel into swictation-daemon");
        println!("2. Add real-time topic detection to pipeline");
        println!("3. Enable adaptive homonym resolution");
        println!("4. Run 2-week beta with user feedback");
    } else if report.improvement_percentage >= 5.0 {
        println!("ğŸ”„ ITERATE");
        println!();
        println!(
            "Shows promise ({:.1}% improvement) but needs tuning.",
            report.improvement_percentage
        );
        println!();
        println!("Suggested improvements:");
        println!(
            "1. Collect more training data (current: {} segments)",
            data.segments.len()
        );
        println!("2. Tune confidence thresholds");
        println!("3. Add more homonym examples");
        println!("4. Refine topic clustering parameters");
    } else {
        println!("âŒ DON'T DEPLOY");
        println!();
        println!(
            "Insufficient improvement ({:.1}%).",
            report.improvement_percentage
        );
        println!("Meta-learning did not beat baseline significantly.");
        println!();
        println!("Consider:");
        println!("1. Alternative learning algorithms");
        println!("2. Different feature extraction");
        println!("3. More diverse training data");
    }

    println!();
    println!("Research complete! ğŸ‰");

    Ok(())
}
