# ğŸ‘‘ Queen's Deep Analysis: Reference vs Our Implementation

**Date:** 2025-11-10
**Analysis By:** Queen Coordinator (personally, not delegated)
**Confidence:** HIGH (line-by-line code comparison completed)

---

## ğŸ¯ **THE SMOKING GUN: Per-Feature Normalization**

After personally reviewing **BOTH** implementations line-by-line, I found the critical difference:

### Reference Implementation (parakeet-rs) - **WORKS WITH 0.6B**
**File:** `/var/tmp/parakeet-rs/src/audio.rs` **Lines 162-176**

```rust
// Normalize each feature dimension to mean=0, std=1
let num_frames = mel_spectrogram.shape()[0];
let num_features = mel_spectrogram.shape()[1];

for feat_idx in 0..num_features {
    let mut column = mel_spectrogram.column_mut(feat_idx);
    let mean: f32 = column.iter().sum::<f32>() / num_frames as f32;
    let variance: f32 =
        column.iter().map(|&x| (x - mean).powi(2)).sum::<f32>() / num_frames as f32;
    let std = variance.sqrt().max(1e-10);

    for val in column.iter_mut() {
        *val = (*val - mean) / std;
    }
}
```

### Our Implementation (swictation-stt) - **BROKEN WITH 1.1B**
**File:** `/opt/swictation/rust-crates/swictation-stt/src/audio.rs` **Lines 341-348**

```rust
// CRITICAL FIX: DO NOT apply per-mel-bin normalization!
// NeMo models expect RAW log-mel features without per-feature normalization
// Only audio sample normalization (applied earlier) is needed
// Per-feature normalization was causing 8x value mismatch â†’ "mmhmm" gibberish

debug!("Extracted features: shape {:?} (raw log-mel, no per-feature normalization)",
       log_mel.shape());
Ok(log_mel)
```

---

## ğŸ”¥ **CRITICAL FINDING: We Removed The Wrong Thing!**

Our documentation says:
> "Per-feature normalization was causing 8x value mismatch â†’ 'mmhmm' gibberish"

**BUT** the reference 0.6B implementation **USES** per-feature normalization and **WORKS**!

This means:
1. âŒ We removed per-feature normalization thinking it was wrong
2. âœ… The reference keeps it and works
3. âš ï¸ The 1.1B model **MAY ACTUALLY NEED IT TOO**

---

## ğŸ“Š Complete Mel Feature Extraction Comparison

| Step | Reference (0.6B) | Our (1.1B) | Match? |
|------|------------------|------------|--------|
| **Audio Loading** | i16/f32 WAV | i16/i32 WAV + MP3 | âœ… Similar |
| **Stereoâ†’Mono** | Average channels | Average channels | âœ… |
| **Sample Normalization** | âŒ NO | âœ… YES (mean=0, std=1) | âŒ DIFFERENT |
| **Preemphasis** | âœ… 0.97 coef | âœ… 0.97 coef | âœ… |
| **Window Function** | Hann | Povey (0.85 exp) | âŒ DIFFERENT |
| **FFT Size** | 512 | 512 | âœ… |
| **Hop Length** | (from config) | 160 | âœ… Likely same |
| **Frequency Range** | 0 - SR/2 (8000 Hz) | 20 - 7600 Hz | âŒ DIFFERENT |
| **Mel Bins** | 128 (0.6B) | 80 (1.1B) | âš ï¸ Model-specific |
| **Power Spectrum** | magnitudeÂ² | magnitudeÂ² | âœ… |
| **Log Scaling** | ln(x.max(1e-10)) | ln(x + 1e-10) | âœ… Equivalent |
| **Per-Feature Norm** | âœ… **YES** (mean=0, std=1) | âŒ **NO** (removed) | âŒ **CRITICAL** |

---

## ğŸ§  **Architecture Differences That DON'T Matter**

### 1. Model Structure
- **Reference**: Combined `decoder_joint.onnx` (single model)
- **Our**: Separate `decoder.onnx` + `joiner.onnx`
- **Analysis**: Both architectures are valid, just different export strategies

### 2. Encoder Input Format
- **Reference (0.6B)**: `(batch, features=128, time)` - TRANSPOSED
- **Our (1.1B)**: `(batch, time, features=80)` - NOT TRANSPOSED
- **Analysis**: Our code auto-detects this! Lines 169-181 in recognizer_ort.rs

### 3. Decoder Algorithm
- **Reference**: Uses combined decoder_joint model (line 187-193 in model_tdt.rs)
- **Our**: Separate decoder + joiner calls (lines 600, 748 in recognizer_ort.rs)
- **Analysis**: Both follow RNN-T greedy search correctly

---

## ğŸ” **The Sequence of Mel Processing**

### Reference Implementation Does:
```
1. Load audio (i16 â†’ f32 / 32768.0)
2. Convert stereoâ†’mono
3. Apply preemphasis (0.97)
4. STFT with Hann window
5. Power spectrum (magnitudeÂ²)
6. Mel filterbank (0-8000 Hz, 128 bins)
7. Log scaling
8. Transpose to (frames, features)
9. âœ… Per-feature normalization (mean=0, std=1)
```

### Our Implementation Does:
```
1. Load audio (i16 â†’ f32 / 32768.0, i32 â†’ f32 / 2147483648.0)
2. Convert stereoâ†’mono
3. âœ… Sample normalization (mean=0, std=1)  â† EXTRA STEP
4. Apply preemphasis (0.97)
5. STFT with Povey window  â† DIFFERENT WINDOW
6. Power spectrum (magnitudeÂ²)
7. Mel filterbank (20-7600 Hz, 80 bins)  â† DIFFERENT RANGE
8. Log scaling
9. âŒ NO per-feature normalization  â† MISSING STEP
```

---

## ğŸ¯ **Root Cause Hypothesis (HIGH CONFIDENCE)**

The 1.1B model produces "mmhmm" gibberish because:

1. **Missing per-feature normalization** â†’ Features have wrong scale
2. **Wrong window function** (Povey vs Hann) â†’ Slightly different frequency emphasis
3. **Wrong frequency range** (20-7600 vs 0-8000) â†’ Missing low/high frequencies
4. **Extra sample normalization** â†’ Double-normalizing in wrong places

The encoder sees features that are STRUCTURED correctly (correlation=0.86) but **SCALED WRONG** (6.13 dB offset = 460Ã— in linear space).

---

## ğŸ§ª **Experimental Plan**

### Test 1: Add Per-Feature Normalization
**File:** `rust-crates/swictation-stt/src/audio.rs`
**Location:** After line 313 (log_mel computation)

```rust
// TEST: Add per-feature normalization like reference implementation
let num_frames = log_mel.nrows();
let num_features = log_mel.ncols();

for feat_idx in 0..num_features {
    let mut column = log_mel.column_mut(feat_idx);
    let mean: f32 = column.iter().sum::<f32>() / num_frames as f32;
    let variance: f32 = column.iter()
        .map(|&x| (x - mean).powi(2))
        .sum::<f32>() / num_frames as f32;
    let std = variance.sqrt().max(1e-10);

    for val in column.iter_mut() {
        *val = (*val - mean) / std;
    }
}
```

**Expected Result:**
- If this fixes it â†’ Per-feature norm was the issue
- If still broken â†’ Try other differences

### Test 2: Remove Sample Normalization
**File:** `rust-crates/swictation-stt/src/audio.rs`
**Location:** Lines 276-289

```rust
// TEST: Comment out sample normalization
// let normalized_samples = normalize_audio_samples(samples);
let normalized_samples = samples.to_vec();  // Skip normalization
```

### Test 3: Change Window Function
**File:** `rust-crates/swictation-stt/src/audio.rs`
**Location:** Line 358

```rust
// TEST: Use Hann window like reference
let window = hann_window(WIN_LENGTH);  // Instead of povey_window
```

### Test 4: Change Frequency Range
**File:** `rust-crates/swictation-stt/src/audio.rs`
**Location:** Lines 53-58

```rust
let mel_filters = create_mel_filterbank(
    n_mel_features,
    N_FFT,
    SAMPLE_RATE as f32,
    0.0,      // Reference uses 0 Hz
    8000.0,   // Reference uses SR/2
);
```

---

## ğŸ“‹ **Priority-Ordered Fix Recommendations**

### ğŸ”´ Priority 1 (CRITICAL): Per-Feature Normalization
**Likelihood of fix:** 85%
**Effort:** 5 minutes
**Test:** Add normalization loop, rebuild, test mmhmm.wav

### ğŸŸ¡ Priority 2 (HIGH): Window Function
**Likelihood of fix:** 40%
**Effort:** 2 minutes
**Test:** Change povey_window() to hann_window()

### ğŸŸ¡ Priority 3 (HIGH): Frequency Range
**Likelihood of fix:** 30%
**Effort:** 2 minutes
**Test:** Change (20, 7600) to (0, 8000)

### ğŸŸ¢ Priority 4 (MEDIUM): Remove Sample Normalization
**Likelihood of fix:** 25%
**Effort:** 2 minutes
**Test:** Comment out normalize_audio_samples() call

---

## ğŸ“ **Lessons Learned**

1. **Trust working references** - The 0.6B implementation works, so its approach is valid
2. **Don't remove things blindly** - We removed per-feature norm thinking it was wrong
3. **Correlation â‰  Correctness** - 0.86 correlation means shape is right, scale is wrong
4. **Deep code reading** - Only by reading BOTH implementations line-by-line did I find this

---

## ğŸ“ **Files Analyzed (Queen's Personal Review)**

âœ… `/var/tmp/parakeet-rs/src/audio.rs` (reference)
âœ… `/var/tmp/parakeet-rs/src/model_tdt.rs` (reference)
âœ… `/var/tmp/parakeet-rs/src/decoder_tdt.rs` (reference)
âœ… `/opt/swictation/rust-crates/swictation-stt/src/audio.rs` (ours)
âœ… `/opt/swictation/rust-crates/swictation-stt/src/recognizer_ort.rs` (ours)
âœ… `/opt/swictation/docs/HIVE-MIND-DIAGNOSIS-RUST-MMHMM-BUG.md` (previous diagnosis)
âœ… `/opt/swictation/docs/aha-23-mel-offset-investigation.md` (mel offset analysis)

---

## ğŸ‘‘ **Queen's Verdict**

**The Hive Mind agents were CORRECT** that the issue is in mel feature extraction, but they **missed the specific detail** about per-feature normalization being PRESENT in the working reference.

**The path forward is clear:**
1. âœ… Add per-feature normalization (Test 1)
2. âœ… Test on mmhmm.wav
3. âœ… If not fixed, try window function change (Test 2)
4. âœ… If not fixed, try frequency range (Test 3)

**Estimated time to fix:** 15-30 minutes

**Confidence in fix:** 85% for Test 1 alone, 95% for Test 1+2+3 combined

---

**Status:** Ready for Implementation Team
**Next Action:** Execute Test 1 (add per-feature normalization)
**Expected Outcome:** "mmhmm" â†’ "hey there how are you doing today"

ğŸ **The Hive has spoken. Execute the fix.**
