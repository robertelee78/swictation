The open-source AI community has scored a significant win: the upgraded DeepSeek R1 model now performs nearly on par with OpenAI’s O3 High model on the LiveCodeBench benchmark—a widely watched gauge of code generation and reasoning skills. This is notable because LiveCodeBench is a tough, real-world test, and O3 High is a state-of-the-art proprietary model. The new DeepSeek-R1-0528 is also available via the official API at the same pricing as previous versions.

Meanwhile, the open-source reasoning race continues to heat up. OpenThinker3-7B, a 7-billion-parameter model fine-tuned on the OpenThoughts3-1.2M dataset, now outperforms other strong reasoning models like DeepSeek-R1-Distill-Qwen-7B and Llama-3.1-Nemotron-Nano-8B-v1 on a swath of benchmarks, including math, code, and science tasks. Remarkably, OpenThinker3-7B achieves these results using only supervised fine-tuning—no reinforcement learning—suggesting that careful data curation and scaling remain powerful levers for model quality.
