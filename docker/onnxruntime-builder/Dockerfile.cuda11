# ONNX Runtime Builder for Maxwell GPU Support (CUDA 11.8 + cuDNN 8.9.7)
#
# This Dockerfile creates a build environment specifically for Maxwell/Pascal/Volta GPUs (sm_50-70)
# using CUDA 11.8 (last stable CUDA 11.x) and cuDNN 8.9.7 (officially recommended for Maxwell).
#
# CRITICAL: cuDNN 8.9.7 must be manually downloaded from NVIDIA Developer
# Download from: https://developer.nvidia.com/rdp/cudnn-archive
# File: cudnn-linux-x86_64-8.9.7.29_cuda11-archive.tar.xz
# Place in this directory before building!

FROM nvidia/cuda:11.8.0-devel-ubuntu22.04

LABEL maintainer="robert@agidreams.us"
LABEL description="ONNX Runtime builder with CUDA 11.8 + cuDNN 8.9.7 for Maxwell GPU support"
LABEL cuda_version="11.8.0"
LABEL cudnn_version="8.9.7"
LABEL target_architectures="sm_50,52,60,61,70"

# Prevent interactive prompts during apt install
ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=UTC

# Install build dependencies
RUN apt-get update && apt-get install -y \
    git \
    wget \
    curl \
    build-essential \
    software-properties-common \
    libssl-dev \
    zlib1g-dev \
    python3.10 \
    python3.10-dev \
    python3-pip \
    && rm -rf /var/lib/apt/lists/*

# Install CMake 3.28+ (ONNX Runtime requires 3.27+)
RUN wget https://github.com/Kitware/CMake/releases/download/v3.28.3/cmake-3.28.3-linux-x86_64.tar.gz \
    && tar -xzf cmake-3.28.3-linux-x86_64.tar.gz -C /opt \
    && rm cmake-3.28.3-linux-x86_64.tar.gz \
    && ln -s /opt/cmake-3.28.3-linux-x86_64/bin/cmake /usr/local/bin/cmake \
    && ln -s /opt/cmake-3.28.3-linux-x86_64/bin/ctest /usr/local/bin/ctest

# Install Python packages needed for ONNX Runtime build
RUN pip3 install --no-cache-dir \
    numpy \
    packaging \
    wheel \
    setuptools

# Install cuDNN 8.9.7 for CUDA 11.8
# NOTE: This file must be present in the build context!
# Download from: https://developer.nvidia.com/rdp/cudnn-archive
# Direct link (requires NVIDIA login):
#   https://developer.nvidia.com/downloads/compute/cudnn/secure/8.9.7/local_installers/11.x/cudnn-linux-x86_64-8.9.7.29_cuda11-archive.tar.xz
COPY cudnn-linux-x86_64-8.9.7.29_cuda11-archive.tar.xz /tmp/

RUN cd /tmp \
    && tar -xf cudnn-linux-x86_64-8.9.7.29_cuda11-archive.tar.xz \
    && cp -r cudnn-linux-x86_64-8.9.7.29_cuda11-archive/include/* /usr/local/cuda/include/ \
    && cp -r cudnn-linux-x86_64-8.9.7.29_cuda11-archive/lib/* /usr/local/cuda/lib64/ \
    && chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn* \
    && ldconfig \
    && rm -rf /tmp/cudnn-*

# Verify cuDNN installation
RUN echo "Verifying cuDNN 8.9.7 installation..." \
    && ldconfig -p | grep cudnn \
    && strings /usr/local/cuda/lib64/libcudnn.so.8 | grep "8.9.7" || echo "WARNING: cuDNN version check failed"

# Set up CUDA paths
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=$CUDA_HOME/bin:$PATH
ENV LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH

# Verify CUDA 11.8 installation
RUN nvcc --version && echo "CUDA 11.8 verified"

# Download ONNX Runtime v1.23.2 (latest stable, no sherpa-onnx version constraints)
# Using latest ONNX Runtime since we removed sherpa-onnx dependency
WORKDIR /workspace
RUN wget https://github.com/microsoft/onnxruntime/archive/refs/tags/v1.23.2.tar.gz \
    && tar -xzf v1.23.2.tar.gz \
    && mv onnxruntime-1.23.2 onnxruntime \
    && rm v1.23.2.tar.gz \
    && cd onnxruntime \
    && git init \
    && git submodule update --init --recursive || echo "Submodules will be handled during build"

# Create build directory
WORKDIR /workspace/onnxruntime
RUN mkdir -p build

# Build script will be mounted from host
# Usage: docker run -v $(pwd)/build-onnxruntime.sh:/workspace/build-onnxruntime.sh onnxruntime-builder:cuda11.8

# Default command
CMD ["/bin/bash"]
